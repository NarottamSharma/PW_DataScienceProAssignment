{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ5F5vrWF/kd+AS677MAIi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hellokrrish/deep_learning/blob/main/Assignment_Introduction_to_Deep_Learning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koJW9nIK4dwK"
      },
      "outputs": [],
      "source": [
        "# Introduction to Deep Learning Assignment questions.\n",
        "\n",
        "# 1.Explain what deep learning is and discuss its significance in the broader field of artificial intelligence.\n",
        "\n",
        "#2. List and explain the fundamental components of artificial neural networks.\n",
        "\n",
        "#3.Discuss the roles of neurons, connections, weights, and biases.\n",
        "\n",
        "# 4.Illustrate the architecture of an artificial neural network. Provide an example to explain the flow of information through the network.\n",
        "\n",
        "\n",
        "# 5.Outline the perceptron learning algorithm. Describe how weights are adjusted during the learning process.\n",
        "\n",
        "\n",
        "# 6.Discuss the importance of activation functions in the hidden layers of a multi-layer perceptron. Provide examples of commonly used activation functions\n",
        "\n",
        " #Various Neural Network Architect Overview Assignments\n",
        "\n",
        "\n",
        "# 1. Describe the basic structure of a Feedforward Neural Network (FNN). What is the purpose of the activation function?\n",
        "\n",
        "\n",
        "# 2 Explain the role of convolutional layers in CNN. Why are pooling layers commonly used, and what do they achieve?\n",
        "\n",
        "# 3 What is the key characteristic that differentiates Recurrent Neural Networks (RNNs) from other neural networks? How does an RNN handle sequential data?\n",
        "\n",
        "# 4 . Discuss the components of a Long Short-Term Memory (LSTM) network. How does it address the vanishing gradient problem?\n",
        "\n",
        "# 5 Describe the roles of the generator and discriminator in a Generative Adversarial Network (GAN). What is the training objective for each?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Introduction to Deep Learning\n",
        "\n",
        "What is Deep Learning and its Significance?\n",
        "\n",
        "Definition: Deep Learning is a subfield of Machine Learning that utilizes artificial neural networks with multiple layers (deep architectures) to learn complex patterns and representations from data.\n",
        "Significance:\n",
        "Powerful Representation Learning: Deep Learning excels at automatically extracting meaningful features from raw data, such as images, text, and audio.\n",
        "Improved Performance: Deep Learning models have achieved state-of-the-art results in various tasks like image recognition, natural language processing, and speech recognition.\n",
        "Driving Innovation: Deep Learning is fueling advancements in fields like autonomous driving, healthcare, and robotics.\n",
        "Fundamental Components of Artificial Neural Networks\n",
        "\n",
        "Neurons: The basic processing units, inspired by biological neurons. They receive input signals, perform a weighted sum, and produce an output.\n",
        "Connections: Links between neurons, representing the flow of information.\n",
        "Weights: Numerical values associated with each connection, determining the strength of the connection.\n",
        "Biases: Constants added to the weighted sum of inputs, introducing a shift in the neuron's activation.\n",
        "Roles of Neurons, Connections, Weights, and Biases\n",
        "\n",
        "Neurons: Process information and transmit signals.\n",
        "Connections: Facilitate the flow of information between neurons.\n",
        "Weights: Determine the importance of each input signal.\n",
        "Biases: Introduce flexibility and allow the network to learn a wider range of functions.\n",
        "Architecture of an Artificial Neural Network\n",
        "\n",
        "Layers: Organized into layers (input, hidden, output).\n",
        "Information Flow: Input data is fed into the input layer, processed through hidden layers, and finally produces an output from the output layer.\n",
        "Example: In an image classification network, the input layer receives pixel values, hidden layers extract features like edges and shapes, and the output layer predicts the class (e.g., cat, dog).\n",
        "Perceptron Learning Algorithm\n",
        "\n",
        "Goal: Adjust weights to minimize the difference between the network's output and the desired output.\n",
        "Weight Updates: Weights are updated iteratively based on the error, using a simple rule like the delta rule.\n",
        "Process:\n",
        "Calculate the error between the predicted output and the actual output.\n",
        "Adjust the weights proportionally to the error.\n",
        "Repeat the process until the error is minimized.\n",
        "Importance of Activation Functions\n",
        "\n",
        "Introduce Non-linearity: Without activation functions, the network would be a simple linear model, limiting its ability to learn complex patterns.\n",
        "Examples:\n",
        "Sigmoid: Outputs values between 0 and 1.\n",
        "ReLU (Rectified Linear Unit): Outputs the input directly if positive, otherwise outputs 0.\n",
        "Tanh: Outputs values between -1 and 1.\n",
        "Various Neural Network Architectures\n",
        "\n",
        "Feedforward Neural Network (FNN)\n",
        "\n",
        "Structure: A simple network where information flows in one direction, from input to output, without loops or cycles.\n",
        "Activation Function: Introduces non-linearity, allowing the network to learn complex relationships.\n",
        "Convolutional Neural Network (CNN)\n",
        "\n",
        "Convolutional Layers: Extract local features by applying filters to the input data (e.g., edges, textures).\n",
        "Pooling Layers: Down-sample the feature maps, reducing dimensionality and making the network more robust to small translations and distortions.\n",
        "Recurrent Neural Network (RNN)\n",
        "\n",
        "Key Characteristic: Contains loops or cycles, allowing information to persist over time.\n",
        "Handling Sequential Data: Can process sequences of data, such as time series, natural language, and music.\n",
        "Long Short-Term Memory (LSTM) Network\n",
        "\n",
        "Components:\n",
        "Forget Gate: Decides which information to discard from the cell state.\n",
        "Input Gate: Decides which information to store in the cell state.\n",
        "Output Gate: Decides which information from the cell state to output.\n",
        "Addressing Vanishing Gradient: The LSTM architecture helps mitigate the vanishing gradient problem by allowing information to flow more effectively through long sequences.\n",
        "Generative Adversarial Network (GAN)\n",
        "\n",
        "Generator: Creates synthetic data samples.\n",
        "Discriminator: Evaluates the generated samples, distinguishing between real and fake data.\n",
        "Training Objective:\n",
        "Generator: To fool the discriminator by generating increasingly realistic samples.\n",
        "Discriminator: To accurately distinguish between real and generated samples.'''"
      ],
      "metadata": {
        "id": "lhwccFMK5LIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}